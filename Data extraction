!apt-get install -y poppler-utils tesseract-ocr
!pip install pdf2image pytesseract pandas

import pytesseract
from pdf2image import convert_from_path
import pandas as pd
import re
from google.colab import files
from concurrent.futures import ThreadPoolExecutor

#Uploading the PDF file
uploaded = files.upload()
pdf_path = list(uploaded.keys())[0]

#Converting PDF pages to images
pages = convert_from_path(pdf_path, dpi=100)
print(f"PDF loaded with {len(pages)} pages.")

#Keywords for identifying financial sections
BALANCE_KEYWORDS = ["balance sheet", "equity", "assets", "liabilities", "reserves"]
PL_KEYWORDS = ["profit and loss", "statement of profit", "revenue", "expenses", "income", "eps", "earning"]
OTHER_KEYWORDS = ["cash flow", "fund flow"]
KEEP_KEYWORDS = BALANCE_KEYWORDS + PL_KEYWORDS + OTHER_KEYWORDS

def detect_section(text):
    t = text.lower()
    if any(k in t for k in BALANCE_KEYWORDS):
        return "balance"
    if any(k in t for k in PL_KEYWORDS):
        return "pl"
    if any(k in t for k in OTHER_KEYWORDS):
        return "other"
    return None

def is_relevant_row(line):
    return any(k in line.lower() for k in KEEP_KEYWORDS)

def parse_line(line):
    numbers = re.findall(r"[-]?\d{1,3}(?:,\d{3})*(?:\.\d+)?", line)
    numbers = [float(num.replace(",", "")) for num in numbers]
    label = re.split(r"[-]?\d{1,3}(?:,\d{3})*(?:\.\d+)?", line, 1)[0].strip()
    return {"Particular": label, "Values": numbers}

#OCR processing for a single page
def process_page(args):
    page_num, page = args
    print(f"Processing page {page_num}...")

    text = pytesseract.image_to_string(page, lang="eng")
    num_count = len(re.findall(r"[-]?\d{1,3}(?:,\d{3})*(?:\.\d+)?", text))

    if num_count < 10:
        print(f"Skipping page {page_num}: too few numeric entries.")
        return None, []

    section = detect_section(text)
    if not section:
        print(f"Skipping page {page_num}: section not identified.")
        return None, []

    rows = []
    for line in text.split("\n"):
        if line.strip() and is_relevant_row(line):
            parsed = parse_line(line)
            if parsed["Values"]:
                rows.append(parsed)

    print(f"Page {page_num} classified as '{section}' with {len(rows)} entries.")
    return section, rows

#Processing pages using multithreading
balance_rows, pl_rows, other_rows = [], [], []
with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(process_page, enumerate(pages, start=1)))

for section, rows in results:
    if section == "balance":
        balance_rows.extend(rows)
    elif section == "pl":
        pl_rows.extend(rows)
    elif section == "other":
        other_rows.extend(rows)

#Converting parsed data to DataFrames
def expand_to_df(rows):
    if not rows:
        return pd.DataFrame()
    max_len = max(len(r["Values"]) for r in rows)
    for r in rows:
        for i in range(max_len):
            r[f"col{i+1}"] = r["Values"][i] if i < len(r["Values"]) else None
        del r["Values"]
    return pd.DataFrame(rows)

df_balance = expand_to_df(balance_rows)
df_pl = expand_to_df(pl_rows)
df_other = expand_to_df(other_rows)

#Saving and downloading the results
if not df_balance.empty:
    df_balance.to_csv("balance_sheet.csv", index=False)
    files.download("balance_sheet.csv")

if not df_pl.empty:
    df_pl.to_csv("profit_loss.csv", index=False)
    files.download("profit_loss.csv")

if not df_other.empty:
    df_other.to_csv("other_financials.csv", index=False)
    files.download("other_financials.csv")

print("Extraction completed successfully.")
